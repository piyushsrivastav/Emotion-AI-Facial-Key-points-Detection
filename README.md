# Emotion-AI-Facial-Key-points-Detection
## The aim of this project is to classify people’s emotions based on their face images.
• In this case study, I build, train a system that automatically monitors
people emotions and expressions.
• The data team has collected more than 20000 facial images,
with their associated facial expression labels and around
2000 images with their facial key-point annotations.

![image](https://user-images.githubusercontent.com/92087972/213907011-ef813979-dc95-468f-bbd4-2923ce4d42fb.png)
![image](https://user-images.githubusercontent.com/92087972/213907027-17b58d73-9d45-4804-aa27-c3d79e7aeaee.png)

## We will create a deep learning model based on Convolutional Neural Network and Residual Blocks to predict facial key-points.

## The dataset consists of x and y coordinates of 15 facial key points.
• Input Images are 96 x 96 pixels.
• Images consist of only one color channel (gray-scale images)

![image](https://user-images.githubusercontent.com/92087972/213907072-0f4a20e1-4dec-4d9e-9599-7b11fcff9aed.png)

## The second model will classify people’s emotion.
• Data contains images that belong to 5 categories:
• 0 = Angry
• 1 = Disgust
• 2 = Sad
• 3 = Happy
• 4 = Surprise
![image](https://user-images.githubusercontent.com/92087972/213907101-3d82f526-1271-42b3-b828-e884c8ce3c3b.png)
![image](https://user-images.githubusercontent.com/92087972/213907114-25a29a81-b1d5-4479-bce0-893a6b9d3256.png)
